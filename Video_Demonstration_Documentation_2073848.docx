Video Demonstration Documentation

Module: Sound and Music Programming
Student Name: Sarliya Ragunathan
Student Number: 2073848

Overview of the Demonstration

The accompanying video demonstrates a simple synthesiser implemented in SuperCollider as part of the Sound and Music Programming assignment. The purpose of the video is to show that the software runs correctly and to demonstrate how different parameters affect the generated sound.

Description of the Software

The software consists of a single SynthDef that generates sound using a sine wave oscillator (SinOsc). The sound is shaped using a percussive amplitude envelope created with EnvGen and Env.perc. The synthesiser outputs stereo audio and automatically frees itself after the sound finishes using doneAction: 2.

The SynthDef includes two main parameters:

freq: controls the pitch of the sound

amp: controls the amplitude (loudness) of the sound

What Is Shown in the Video

In the video, the following steps are demonstrated:

The SuperCollider audio server is booted.

The SynthDef is evaluated to load it onto the server.

Multiple Synth instances are created using different parameter values.

Changes in frequency result in audible pitch differences.

Changes in amplitude result in differences in loudness, although these may be subtle due to the short percussive envelope.

This demonstrates that the SynthDef responds correctly to parameter changes and produces sound as expected.

Explanation of Sound Behaviour

The sound produced is short and percussive, which means that changes in amplitude may be less noticeable than changes in pitch. This is due to the short envelope duration and the way human hearing perceives loudness. Despite this, the amplitude parameter is functioning correctly and provides control over output level.

Use of AI Tools

AI tools (ChatGPT) were used during development to help check whether the code was functioning as intended and to understand why certain behaviours occurred, such as why parameter changes were not initially producing audible differences or why Synths did not automatically stop.

AI was used as a support tool for debugging and understanding, not for generating the entire project. All final code decisions were made by the author, and all AI use is documented in the AI Collaboration Portfolio.

Conclusion

The video demonstrates a working SuperCollider synthesiser that meets the aims of the assignment by showing basic sound synthesis concepts, parameter control, and correct resource management. The project prioritises clarity and understanding over complexity and successfully fulfils the requirements of the assessment.
